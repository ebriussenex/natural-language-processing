{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNtLJlW4v5VF"
   },
   "source": [
    "## Классификация текстов с использованием предобученных языковых моделей.\n",
    "\n",
    "В данном задании вам предстоит обратиться к задаче классификации текстов и решить ее с использованием предобученной модели BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "%matplotlib inline\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратимся к набору данных SST-2. Holdout часть данных (которая понадобится вам для посылки) доступна по ссылке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "!wget https://raw.githubusercontent.com/girafe-ai/ml-course/refs/heads/24f_yandex_ml_trainings/homeworks/hw04_bert_and_co/texts_holdout.json\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "df = pd.read_csv(\n",
    "    \"https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv\",\n",
    "    delimiter=\"\\t\",\n",
    "    header=None,\n",
    ")\n",
    "texts_train = df[0].values[:5000]\n",
    "y_train = df[1].values[:5000]\n",
    "texts_test = df[0].values[5000:]\n",
    "y_test = df[1].values[5000:]\n",
    "with open(\"texts_holdout.json\") as iofile:\n",
    "    texts_holdout = json.load(iofile)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весь остальной код предстоит написать вам.\n",
    "\n",
    "Для успешной сдачи на максимальный балл необходимо добиться хотя бы __84.5% accuracy на тестовой части выборки__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your beautiful experiments here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сдача взадания в контест\n",
    "Сохраните в словарь `out_dict` вероятности принадлежности к первому (положительному) классу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {\n",
    "    'train': # list of length 5000 with probas\n",
    "    'test': # list of length 1920 with probas\n",
    "    'holdout': # list of length 500 with probas\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько `assert`'ов для проверки вашей посылки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(out_dict[\"train\"], list), \"Object must be a list of floats\"\n",
    "assert isinstance(out_dict[\"train\"][0], float), \"Object must be a list of floats\"\n",
    "assert (\n",
    "    len(out_dict[\"train\"]) == 5000\n",
    "), \"The predicted probas list length does not match the train set size\"\n",
    "\n",
    "assert isinstance(out_dict[\"test\"], list), \"Object must be a list of floats\"\n",
    "assert isinstance(out_dict[\"test\"][0], float), \"Object must be a list of floats\"\n",
    "assert (\n",
    "    len(out_dict[\"test\"]) == 1920\n",
    "), \"The predicted probas list length does not match the test set size\"\n",
    "\n",
    "assert isinstance(out_dict[\"holdout\"], list), \"Object must be a list of floats\"\n",
    "assert isinstance(out_dict[\"holdout\"][0], float), \"Object must be a list of floats\"\n",
    "assert len(\n",
    "    out_dict[\"holdout\"] == 500\n",
    "), \"The predicted probas list length does not match the holdout set size\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите код ниже для генерации посылки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "FILENAME = \"submission_dict_hw_text_classification_with_bert.json\"\n",
    "\n",
    "with open(FILENAME, \"w\") as iofile:\n",
    "    json.dump(out_dict, iofile)\n",
    "print(f\"File saved to `{FILENAME}`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_hw01_texts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "coach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
